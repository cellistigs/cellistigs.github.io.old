<html>
<head>
    <link rel="Stylesheet" type="text/css" href="style.css" />
    <title>Wednesday</title>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
</head>
<body> 
    <a href="index.html">Index</a> |
    <a href="diary/diary.html">Diary</a>
    <hr>
    <div class="content">
    
<ul>
<li>
Check claire data (10 mins) 

<ul>
<li>
issues with neurocaas_contrib monitor function with <code>init</code>. Look into this.  

<li>
we could keep per-analysis development state in the folders themselves. 

</ul>
<li>
Try silvia and paul (10 mins)

<ul>
<li>
flat stack of tif files. get feedback on data organization. 

</ul>
<li>
Heilmeyer catcechism (10 mins) 

<ul>
<li>
What are you trying to do? Articulate your objectives with absolutely no jargon. 

<ul>
<li>
I will design methods to explicitly improve the <span id="-reliability"></span><strong id="reliability">reliability</strong> of automatic approaches to tracking animal posture.  

<ul>
<li>
beyond doing the task well, I will create methods that tell you when they cannot do the task well.  

</ul>
<li>
I am trying to improve the automatic tracking of animal posture. I am trying to create a prescription by which 

</ul>
<li>
How is it done now? What are the limitations of current approaches? 

<ul>
<li>
The limitations of current approaches is that there is an unboundedness to the increase in performance of pose tracking 

</ul>
<li>
What is new in your approach? Why do you think it will be successful?   

<li>
Who cares? What will be the impact? 

<li>
What are the risks?

<li>
How much will it cost?

<li>
How long will it take? 

<li>
What are analyzable milestones along your path? 

</ul>
<li>
Aim 2 redirect (1 hr-1.5 hrs) 

<ul>
<li>
Read Generalization Bounds Encyclopedia article. 

<li>
Skimmed arbib Learning and Generalization 
      Skimmed algorithmic luckiness. 

<ul>
<li>
Generalization bounds work cares about the difference between training and test error in most cases across all possible training samples. 

<li>
Luckiness is a measure of how easy a particular sample is to learn given a particular hypothesis class/algorithm. 

<li>
Algorithmic stability studies the effect of removing some training examples on others. 

<li>
How do you trust more than your specific model?  

</ul>
</ul>
<li>
Catherine (wednesday) 

<ul>
<li>
Do you want to work on neurocaas/if so, where

</ul>
<li>
Andres (wednesday)

<ul>
<li>
Advice: Have some scientific questions Youre interested in asking. Methods can be changed. 

</ul>
<li>
Max (wednesday) 

<ul>
<li>
Review schedule

<li>
Actionables for our collaborators

<li>
Weekly check ins/slack for technical discussion? 

</ul>
<li>
New schedule that does not explode and gets to target in 10k iterations 

<ul>
<li>
linear warmup looks pretty bad. try log. 

</ul>
<li>
Document and label some data

<ul>
<li>
document is done

<li>
label still needs to be done. 

</ul>
<li>
Groceries

<li>
Text tom 

<li>
Clean ac

</ul>

    </div>
    <p><small>Page created on 2021-09-08</small></p>
</body>
</html>
