<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <id>https://cellistigs.github.io</id>
  <title>taiga_projectdoc Blog</title>
  <updated>2021-08-10T21:32:28.544744+00:00</updated>
  <link href="https://cellistigs.github.io"/>
  <link href="https://cellistigs.github.io/blog/atom.xml" rel="self"/>
  <generator uri="https://ablog.readthedocs.org/" version="0.10.19">ABlog</generator>
  <entry>
    <id>https://cellistigs.github.io/Literature/darrell_selfsupervise/</id>
    <title>Trevor Darrell’s Self Supervision Papers</title>
    <updated>2020-08-10T00:00:00-04:00</updated>
    <content type="html">&lt;p&gt;Due to the ensembling results I was getting, John recommended that I take a look at Trevor Darrell’s recent work with self supervised learning. Here I’m going to describe two papers by his group (&lt;span id="id1"&gt;[]&lt;/span&gt;) that apply self supervision to the task of representation learning- learning good representations that you can use to initialize networks for a variety of downstream tasks. In general, lots of work in self supervision is then evaluated by sticking on a linear layer at the top, which gets trained for certain downstream tasks (sometimes the main network is fine tuned, sometimes not). In general though, these self supervision papers assume the goal of self supervision is good representation learning for downstream tasks, which is a little different from what I’m doing.&lt;/p&gt;
</content>
    <link href="https://cellistigs.github.io/Literature/darrell_selfsupervise/" rel="alternate"/>
    <summary>Due to the ensembling results I was getting, John recommended that I take a look at Trevor Darrell’s recent work with self supervised learning. Here I’m going to describe two papers by his group (Reed.2020,Reed.2021) that apply self supervision to the task of representation learning- learning good representations that you can use to initialize networks for a variety of downstream tasks. In general, lots of work in self supervision is then evaluated by sticking on a linear layer at the top, which gets trained for certain downstream tasks (sometimes the main network is fine tuned, sometimes not). In general though, these self supervision papers assume the goal of self supervision is good representation learning for downstream tasks, which is a little different from what I’m doing.</summary>
    <category term="self-supervisedlearning" label="self-supervised learning"/>
    <category term="dataaugmentation" label="data augmentation"/>
    <published>2020-08-10T00:00:00-04:00</published>
  </entry>
</feed>
